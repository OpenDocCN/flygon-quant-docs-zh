["```py\n$  zipline  bundles\nmy-custom-bundle  2016-05-05  20:35:19.809398\nmy-custom-bundle  2016-05-05  20:34:53.654082\nmy-custom-bundle  2016-05-05  20:34:48.401767\nquandl  2016-05-05  20:06:40.894956 \n```", "```py\n$  zipline  ingest  [-b  <bundle>] \n```", "```py\n# clean everything older than <date>\n$  zipline  clean  [-b  <bundle>]  --before  <date>\n\n# clean everything newer than <date>\n$  zipline  clean  [-b  <bundle>]  --after  <date>\n\n# keep everything in the range of [before, after] and delete the rest\n$  zipline  clean  [-b  <bundle>]  --before  <date>  --after  <after>\n\n# clean all but the last <int> runs\n$  zipline  clean  [-b  <bundle>]  --keep-last  <int> \n```", "```py\n$  zipline  run  --bundle  <bundle>  --algofile  algo.py  ... \n```", "```py\n$  zipline  ingest  -b  quandl\n$  zipline  ingest \n```", "```py\ningest(environ,\n       asset_db_writer,\n       minute_bar_writer,\n       daily_bar_writer,\n       adjustment_writer,\n       calendar,\n       start_session,\n       end_session,\n       cache,\n       show_progress,\n       output_dir) \n```", "```py\ndate,open,high,low,close,volume,dividend,split\n2012-01-03,58.485714,58.92857,58.42857,58.747143,75555200,0.0,1.0\n2012-01-04,58.57143,59.240002,58.468571,59.062859,65005500,0.0,1.0\n2012-01-05,59.278572,59.792858,58.952858,59.718571,67817400,0.0,1.0\n2012-01-06,59.967144,60.392857,59.888573,60.342857,79573200,0.0,1.0\n2012-01-09,60.785713,61.107143,60.192856,60.247143,98506100,0.0,1.0\n2012-01-10,60.844284,60.857143,60.214287,60.462856,64549100,0.0,1.0\n2012-01-11,60.382858,60.407143,59.901428,60.364285,53771200,0.0,1.0 \n```", "```py\nimport pandas as pd\n\nfrom zipline.data.bundles import register\nfrom zipline.data.bundles.csvdir import csvdir_equities \n```", "```py\nstart_session = pd.Timestamp('2016-1-1', tz='utc')\nend_session = pd.Timestamp('2018-1-1', tz='utc') \n```", "```py\nregister(\n    'custom-csvdir-bundle',\n    csvdir_equities(\n        ['daily'],\n        '/path/to/your/csvs',\n    ),\n    calendar_name='NYSE', # US equities\n    start_session=start_session,\n    end_session=end_session\n) \n```", "```py\n$  zipline  ingest  -b  custom-csvdir-bundle\nLoading  custom  pricing  data:  [############------------------------]   33% | FAKE: sid 0\nLoading  custom  pricing  data:  [########################------------]   66% | FAKE1: sid 1\nLoading  custom  pricing  data:  [####################################]  100% | FAKE2: sid 2\nLoading  custom  pricing  data:  [####################################]  100%\nMerging  daily  equity  files:  [####################################]\n\n# optionally, we can pass the location of our csvs via the command line\n$  CSVDIR=/path/to/your/csvs  zipline  ingest  -b  custom-csvdir-bundle \n```", "```py\n$  zipline  bundles\nmy-custom-bundle  2016-05-05  20:35:19.809398\nmy-custom-bundle  2016-05-05  20:34:53.654082\nmy-custom-bundle  2016-05-05  20:34:48.401767\nquandl  2016-05-05  20:06:40.894956 \n```", "```py\n$  zipline  ingest  [-b  <bundle>] \n```", "```py\n# clean everything older than <date>\n$  zipline  clean  [-b  <bundle>]  --before  <date>\n\n# clean everything newer than <date>\n$  zipline  clean  [-b  <bundle>]  --after  <date>\n\n# keep everything in the range of [before, after] and delete the rest\n$  zipline  clean  [-b  <bundle>]  --before  <date>  --after  <after>\n\n# clean all but the last <int> runs\n$  zipline  clean  [-b  <bundle>]  --keep-last  <int> \n```", "```py\n$  zipline  run  --bundle  <bundle>  --algofile  algo.py  ... \n```", "```py\n$  zipline  ingest  -b  quandl\n$  zipline  ingest \n```", "```py\n$  zipline  ingest  -b  quandl\n$  zipline  ingest \n```", "```py\ningest(environ,\n       asset_db_writer,\n       minute_bar_writer,\n       daily_bar_writer,\n       adjustment_writer,\n       calendar,\n       start_session,\n       end_session,\n       cache,\n       show_progress,\n       output_dir) \n```", "```py\ndate,open,high,low,close,volume,dividend,split\n2012-01-03,58.485714,58.92857,58.42857,58.747143,75555200,0.0,1.0\n2012-01-04,58.57143,59.240002,58.468571,59.062859,65005500,0.0,1.0\n2012-01-05,59.278572,59.792858,58.952858,59.718571,67817400,0.0,1.0\n2012-01-06,59.967144,60.392857,59.888573,60.342857,79573200,0.0,1.0\n2012-01-09,60.785713,61.107143,60.192856,60.247143,98506100,0.0,1.0\n2012-01-10,60.844284,60.857143,60.214287,60.462856,64549100,0.0,1.0\n2012-01-11,60.382858,60.407143,59.901428,60.364285,53771200,0.0,1.0 \n```", "```py\nimport pandas as pd\n\nfrom zipline.data.bundles import register\nfrom zipline.data.bundles.csvdir import csvdir_equities \n```", "```py\nstart_session = pd.Timestamp('2016-1-1', tz='utc')\nend_session = pd.Timestamp('2018-1-1', tz='utc') \n```", "```py\nregister(\n    'custom-csvdir-bundle',\n    csvdir_equities(\n        ['daily'],\n        '/path/to/your/csvs',\n    ),\n    calendar_name='NYSE', # US equities\n    start_session=start_session,\n    end_session=end_session\n) \n```", "```py\n$  zipline  ingest  -b  custom-csvdir-bundle\nLoading  custom  pricing  data:  [############------------------------]   33% | FAKE: sid 0\nLoading  custom  pricing  data:  [########################------------]   66% | FAKE1: sid 1\nLoading  custom  pricing  data:  [####################################]  100% | FAKE2: sid 2\nLoading  custom  pricing  data:  [####################################]  100%\nMerging  daily  equity  files:  [####################################]\n\n# optionally, we can pass the location of our csvs via the command line\n$  CSVDIR=/path/to/your/csvs  zipline  ingest  -b  custom-csvdir-bundle \n```"]